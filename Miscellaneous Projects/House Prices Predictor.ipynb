{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the data\n",
    "\n",
    "The data for this project has been obtained from Kaggle. The dataset contains a collection of 1460 individual properties with 81 attributes.\n",
    "\n",
    "### Research collection\n",
    "\n",
    "Using the 81 attributes and a rather limited number of samples, can we build a sufficiently accurate model for estimating property values in Ames, Iowa?\n",
    "\n",
    "### Source\n",
    "\n",
    "House Prices: Advanced Regression Techniques\n",
    "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data\n",
    "\n",
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mhuh22\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# Necessary imports\n",
    "import os\n",
    "import time\n",
    "import timeit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import resample\n",
    "%matplotlib inline\n",
    "\n",
    "# Modelling packages\n",
    "from sklearn import ensemble, linear_model\n",
    "from sklearn.feature_selection import chi2, f_classif, SelectKBest \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import adjusted_rand_score, classification_report, confusion_matrix, silhouette_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Plotly packages\n",
    "import cufflinks as cf\n",
    "import ipywidgets as widgets\n",
    "import plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "from scipy import special\n",
    "py.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "housing_train = pd.read_csv(\"train.csv\")\n",
    "housing_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Drop the 'id' column since it's not a predictor\n",
    "housing_train.drop(['Id'], axis=1, inplace=True)\n",
    "\n",
    "# Preview the dataset\n",
    "housing_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the size of the dataframe\n",
    "housing_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all 80 data columns\n",
    "housing_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View number of missing values in each category\n",
    "housing_train.isna().sum().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, quite a few of features seem to be missing values for the majority of data points, like poolqc, misc features, alley, fence, fireplacequ, and lotfrontage. For the columns that are missing an excessive number of values, it seems safe to impute the value of 0 to signify that these traits are not present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values in these categories with 0\n",
    "housing_train[['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'LotFrontage']].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the distribution on sale prices\n",
    "housing_train['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of housing prices\n",
    "sns.distplot(housing_train['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View descriptive statistics for all numerical categories\n",
    "housing_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe unique occurences for each categorical variable\n",
    "housing_train.nunique().sort_values(ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a correlation matrix among the predictor variables\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "\n",
    "correlation_martix = housing_train.corr()\n",
    "sns.heatmap(correlation_martix, vmax = 1, square = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute all remaining missing values with 0s\n",
    "housing_train.fillna(0, inplace=True)\n",
    "housing_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily ignore non-numeric values\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numeric_housing_train = housing_train.select_dtypes(include=numerics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the input and output variables\n",
    "X = numeric_housing_train.drop('SalePrice', axis=1)\n",
    "y = housing_train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the dataset into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe to track runtime and scores\n",
    "models = ['Logistic regression' , 'Random forest']\n",
    "runtime = []\n",
    "train_score = []\n",
    "test_score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_model(model):\n",
    "    \n",
    "#     # Train the model\n",
    "#     start_time = timeit.default_timer()\n",
    "#     train_set = cross_val_score(model, X, y, cv=5, n_jobs=-1)\n",
    "#     elapsed_time = timeit.default_timer() - start_time   \n",
    "    \n",
    "#     # Append the scores and runtime to our dataframe\n",
    "#     train_score.append(train_set.mean())\n",
    "#     runtime.append(elapsed_time)\n",
    "    \n",
    "#     # Fit the model to the data\n",
    "#     model.fit(X, y)\n",
    "    \n",
    "#     # Store the predicted values in a dataframe\n",
    "#     y_pred = model.predict(X)\n",
    "    \n",
    "#     # Print scores and runtime\n",
    "#     print(str(model), '\\n\\nTrain score: {:.5f}(+/- {:.2f})\\n'.format(train_set.mean(), train_set.std()*2))\n",
    "#     print('Runtime:', elapsed_time, 'seconds\\n')\n",
    "    \n",
    "#     # Generate and print the confusion matrix\n",
    "#     print('Confusion matrix:\\n\\n', confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear regression model\n",
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "# Fit the model to the data, and predict values\n",
    "lr.fit(X, y)\n",
    "y_pred = lr.predict(X)\n",
    "\n",
    "# Print the overall accuracy of the model\n",
    "print('Score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing predicted results to actual results\n",
    "plt.title\n",
    "ax = sns.scatterplot(x = 'True Values', \n",
    "                     y = 'Predicted Values', \n",
    "                     data = pd.DataFrame({'True Values': y, 'Predicted Values': y_pred}))\\\n",
    "                    .set_title('Predicted vs Actual Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validate our model\n",
    "cross_val_score = cross_val_score(lr, X, y, cv=5, n_jobs=-1)\n",
    "\n",
    "# Print the results of our cross validation matrix\n",
    "print('Cross validation score: {:.5f}(+/- {:.2f})\\n'.format(cross_val_score.mean(), cross_val_score.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
